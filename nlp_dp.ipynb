{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBmjBYqnuf8w"
   },
   "source": [
    "#NLP - Natural Language Processing\n",
    "######NLP MAKES IT POSSIBLE FOR MACHINE TO READ TEXT , HEAR SPEACH,MESURE SENTIMENT AND DETERMINE WHICH PARTS OF TEXT IS IMPORTANT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otbcbUSOvNI-"
   },
   "source": [
    "NLTK- is toolkit all method are present in this nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mj0OJ_RuQHnH",
    "outputId": "5db1cf7c-ad79-404a-f229-99e94b7788bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "eO2MHkeiOtOA"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEO8jGVAvaFZ"
   },
   "source": [
    "tokenization - is essentially spliting pharse, sentence,paragraph or entrie text document into smaller unites and each unit called as token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "i3Guh8x5O07O"
   },
   "outputs": [],
   "source": [
    "text=\"\"\"Like Mahabharata, Ramayana presents the teachings of ancient Hindu sages in narrative allegory, interspersing philosophical and ethical elements. The characters Rama, Sita, Lakshmana, Bharata, Hanuman, and Ravana are all fundamental to the cultural consciousness of the South Asian nations of India, Nepal, Sri Lanka and the South-East Asian countries of Thailand, Cambodia, Malaysia and Indonesia.There are many versions of Ramayana in Indian languages, besides Buddhist, Sikh, and Jain adaptations. There are also Cambodian, Indonesian, Filipino, Thai, Lao, Burmese and Malay versions of the tale.However, the Singapore government now has confirmed local law enforcement will be able to access the data for criminal investigations. Under the Criminal Procedure Code, the Singapore Police Force can obtain any data and this includes TraceTogether data, according to Minister of State for Home Affairs, Desmond Tan. He was responding to a question posed during parliament Monday on whether the TraceTogether data would be used for criminal probes and the safeguards governing the use of such data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "ArtXn731iuNk",
    "outputId": "a8de1180-b1ff-48a0-e32e-c7f1e9e4d78a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Like Mahabharata, Ramayana presents the teachings of ancient Hindu sages in narrative allegory, interspersing philosophical and ethical elements. The characters Rama, Sita, Lakshmana, Bharata, Hanuman, and Ravana are all fundamental to the cultural consciousness of the South Asian nations of India, Nepal, Sri Lanka and the South-East Asian countries of Thailand, Cambodia, Malaysia and Indonesia.There are many versions of Ramayana in Indian languages, besides Buddhist, Sikh, and Jain adaptations. There are also Cambodian, Indonesian, Filipino, Thai, Lao, Burmese and Malay versions of the tale.However, the Singapore government now has confirmed local law enforcement will be able to access the data for criminal investigations. Under the Criminal Procedure Code, the Singapore Police Force can obtain any data and this includes TraceTogether data, according to Minister of State for Home Affairs, Desmond Tan. He was responding to a question posed during parliament Monday on whether the TraceTogether data would be used for criminal probes and the safeguards governing the use of such data.'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "bZjSFs2_PK-R"
   },
   "outputs": [],
   "source": [
    "sent_token  = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMSijWZpv5aI",
    "outputId": "13572f5a-8f8f-46f7-aad4-a92aadd382b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Like Mahabharata, Ramayana presents the teachings of ancient Hindu sages in narrative allegory, interspersing philosophical and ethical elements.',\n",
       " 'The characters Rama, Sita, Lakshmana, Bharata, Hanuman, and Ravana are all fundamental to the cultural consciousness of the South Asian nations of India, Nepal, Sri Lanka and the South-East Asian countries of Thailand, Cambodia, Malaysia and Indonesia.There are many versions of Ramayana in Indian languages, besides Buddhist, Sikh, and Jain adaptations.',\n",
       " 'There are also Cambodian, Indonesian, Filipino, Thai, Lao, Burmese and Malay versions of the tale.However, the Singapore government now has confirmed local law enforcement will be able to access the data for criminal investigations.',\n",
       " 'Under the Criminal Procedure Code, the Singapore Police Force can obtain any data and this includes TraceTogether data, according to Minister of State for Home Affairs, Desmond Tan.',\n",
       " 'He was responding to a question posed during parliament Monday on whether the TraceTogether data would be used for criminal probes and the safeguards governing the use of such data.']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iGfs3YUTPPmK",
    "outputId": "35384406-1305-4c1b-830a-67f5c1190a5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Like Mahabharata, Ramayana presents the teachings of ancient Hindu sages in narrative allegory, interspersing philosophical and ethical elements.',\n",
       " 'The characters Rama, Sita, Lakshmana, Bharata, Hanuman, and Ravana are all fundamental to the cultural consciousness of the South Asian nations of India, Nepal, Sri Lanka and the South-East Asian countries of Thailand, Cambodia, Malaysia and Indonesia.There are many versions of Ramayana in Indian languages, besides Buddhist, Sikh, and Jain adaptations.']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyqOf-10Qn9x",
    "outputId": "22b760dc-6e44-4363-96cf-8dde37e1938a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_token) # total senetense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3jKSOzgTfm2",
    "outputId": "1eec62b8-245b-4f76-edc1-e138059b2fa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Like',\n",
       " 'Mahabharata',\n",
       " ',',\n",
       " 'Ramayana',\n",
       " 'presents',\n",
       " 'the',\n",
       " 'teachings',\n",
       " 'of',\n",
       " 'ancient',\n",
       " 'Hindu',\n",
       " 'sages',\n",
       " 'in',\n",
       " 'narrative',\n",
       " 'allegory',\n",
       " ',',\n",
       " 'interspersing',\n",
       " 'philosophical',\n",
       " 'and',\n",
       " 'ethical',\n",
       " 'elements',\n",
       " '.',\n",
       " 'The',\n",
       " 'characters',\n",
       " 'Rama',\n",
       " ',',\n",
       " 'Sita',\n",
       " ',',\n",
       " 'Lakshmana',\n",
       " ',',\n",
       " 'Bharata',\n",
       " ',',\n",
       " 'Hanuman',\n",
       " ',',\n",
       " 'and',\n",
       " 'Ravana',\n",
       " 'are',\n",
       " 'all',\n",
       " 'fundamental',\n",
       " 'to',\n",
       " 'the',\n",
       " 'cultural',\n",
       " 'consciousness',\n",
       " 'of',\n",
       " 'the',\n",
       " 'South',\n",
       " 'Asian',\n",
       " 'nations',\n",
       " 'of',\n",
       " 'India',\n",
       " ',',\n",
       " 'Nepal',\n",
       " ',',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " 'and',\n",
       " 'the',\n",
       " 'South-East',\n",
       " 'Asian',\n",
       " 'countries',\n",
       " 'of',\n",
       " 'Thailand',\n",
       " ',',\n",
       " 'Cambodia',\n",
       " ',',\n",
       " 'Malaysia',\n",
       " 'and',\n",
       " 'Indonesia.There',\n",
       " 'are',\n",
       " 'many',\n",
       " 'versions',\n",
       " 'of',\n",
       " 'Ramayana',\n",
       " 'in',\n",
       " 'Indian',\n",
       " 'languages',\n",
       " ',',\n",
       " 'besides',\n",
       " 'Buddhist',\n",
       " ',',\n",
       " 'Sikh',\n",
       " ',',\n",
       " 'and',\n",
       " 'Jain',\n",
       " 'adaptations',\n",
       " '.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'also',\n",
       " 'Cambodian',\n",
       " ',',\n",
       " 'Indonesian',\n",
       " ',',\n",
       " 'Filipino',\n",
       " ',',\n",
       " 'Thai',\n",
       " ',',\n",
       " 'Lao',\n",
       " ',',\n",
       " 'Burmese',\n",
       " 'and',\n",
       " 'Malay',\n",
       " 'versions',\n",
       " 'of',\n",
       " 'the',\n",
       " 'tale.However',\n",
       " ',',\n",
       " 'the',\n",
       " 'Singapore',\n",
       " 'government',\n",
       " 'now',\n",
       " 'has',\n",
       " 'confirmed',\n",
       " 'local',\n",
       " 'law',\n",
       " 'enforcement',\n",
       " 'will',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'access',\n",
       " 'the',\n",
       " 'data',\n",
       " 'for',\n",
       " 'criminal',\n",
       " 'investigations',\n",
       " '.',\n",
       " 'Under',\n",
       " 'the',\n",
       " 'Criminal',\n",
       " 'Procedure',\n",
       " 'Code',\n",
       " ',',\n",
       " 'the',\n",
       " 'Singapore',\n",
       " 'Police',\n",
       " 'Force',\n",
       " 'can',\n",
       " 'obtain',\n",
       " 'any',\n",
       " 'data',\n",
       " 'and',\n",
       " 'this',\n",
       " 'includes',\n",
       " 'TraceTogether',\n",
       " 'data',\n",
       " ',',\n",
       " 'according',\n",
       " 'to',\n",
       " 'Minister',\n",
       " 'of',\n",
       " 'State',\n",
       " 'for',\n",
       " 'Home',\n",
       " 'Affairs',\n",
       " ',',\n",
       " 'Desmond',\n",
       " 'Tan',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'responding',\n",
       " 'to',\n",
       " 'a',\n",
       " 'question',\n",
       " 'posed',\n",
       " 'during',\n",
       " 'parliament',\n",
       " 'Monday',\n",
       " 'on',\n",
       " 'whether',\n",
       " 'the',\n",
       " 'TraceTogether',\n",
       " 'data',\n",
       " 'would',\n",
       " 'be',\n",
       " 'used',\n",
       " 'for',\n",
       " 'criminal',\n",
       " 'probes',\n",
       " 'and',\n",
       " 'the',\n",
       " 'safeguards',\n",
       " 'governing',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'such',\n",
       " 'data',\n",
       " '.']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(text)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILKvOOqyTpru",
    "outputId": "a80982bd-36bc-421b-c1f0-93815ff561bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sages', 'in', 'narrative', 'allegory']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "__my1eOuTqw8"
   },
   "outputs": [],
   "source": [
    "# next part is \n",
    "# steamming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmbjEZApZB4R",
    "outputId": "ac94b69b-c5e4-480e-cab3-66b330a099ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "pYYrI8bHXTgd"
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "nZ-iLbU8XuKX"
   },
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "R56kseQXX1vw"
   },
   "outputs": [],
   "source": [
    "# stop word remove words like -of,and,so,then,as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0V5uDxl6Ytyy",
    "outputId": "3fca8bca-85c8-46bb-d106-6f2a48b182e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which is stop word\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "fRqqaNyVYTeA"
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9ACbiHsly4Q",
    "outputId": "bb7c2e0c-d8f0-4224-8d89-f964391550b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have three visions for India.',\n",
       " 'In 3000 years of our history, people from all over \\n               the world have come and invaded us, captured our lands, conquered our minds.',\n",
       " 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\\n               the French, the Dutch, all of them came and looted us, took over what was ours.',\n",
       " 'Yet we have not done this to any other nation.',\n",
       " 'We have not conquered anyone.',\n",
       " 'We have not grabbed their land, their culture, \\n               their history and tried to enforce our way of life on them.',\n",
       " 'Why?',\n",
       " 'Because we respect the freedom of others.That is why my \\n               first vision is that of freedom.',\n",
       " 'I believe that India got its first vision of \\n               this in 1857, when we started the War of Independence.',\n",
       " 'It is this freedom that\\n               we must protect and nurture and build on.',\n",
       " 'If we are not free, no one will respect us.',\n",
       " 'My second vision for India’s development.',\n",
       " 'For fifty years we have been a developing nation.',\n",
       " 'It is time we see ourselves as a developed nation.',\n",
       " 'We are among the top 5 nations of the world\\n               in terms of GDP.',\n",
       " 'We have a 10 percent growth rate in most areas.',\n",
       " 'Our poverty levels are falling.',\n",
       " 'Our achievements are being globally recognised today.',\n",
       " 'Yet we lack the self-confidence to\\n               see ourselves as a developed nation, self-reliant and self-assured.',\n",
       " 'Isn’t this incorrect?',\n",
       " 'I have a third vision.',\n",
       " 'India must stand up to the world.',\n",
       " 'Because I believe that unless India \\n               stands up to the world, no one will respect us.',\n",
       " 'Only strength respects strength.',\n",
       " 'We must be \\n               strong not only as a military power but also as an economic power.',\n",
       " 'Both must go hand-in-hand.',\n",
       " 'My good fortune was to have worked with three great minds.',\n",
       " 'Dr. Vikram Sarabhai of the Dept.',\n",
       " 'of \\n               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.',\n",
       " 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.',\n",
       " 'I see four milestones in my career']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "-e__wK2FYgXm"
   },
   "outputs": [],
   "source": [
    "steamer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PH_Eo3linhsf",
    "outputId": "55b04615-619d-41d8-8708-4968e2f7552f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Q4ge-sLno9I",
    "outputId": "27050ec9-5048-47c4-e729-f44bb3fb993e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'three', 'visions', 'for', 'India', '.']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(sentences[0])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "TvkonYLaZIcA"
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "  words = nltk.word_tokenize(sentences[i])\n",
    "  words = [steamer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "  sentences[i] = ' '.join(words)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S87GVaOVaWuU",
    "outputId": "d5a76a5c-0023-4c04-f73d-5fb47223338c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I three vision india .',\n",
       " 'In 3000 year histori , peopl world come invad us , captur land , conquer mind .',\n",
       " 'from alexand onward , greek , turk , mogul , portugues , british , french , dutch , came loot us , took .',\n",
       " 'yet done nation .',\n",
       " 'We conquer anyon .',\n",
       " 'We grab land , cultur , histori tri enforc way life .',\n",
       " 'whi ?',\n",
       " 'becaus respect freedom others.that first vision freedom .',\n",
       " 'I believ india got first vision 1857 , start war independ .',\n",
       " 'It freedom must protect nurtur build .',\n",
       " 'If free , one respect us .',\n",
       " 'My second vision india ’ develop .',\n",
       " 'for fifti year develop nation .',\n",
       " 'It time see develop nation .',\n",
       " 'We among top 5 nation world term gdp .',\n",
       " 'We 10 percent growth rate area .',\n",
       " 'our poverti level fall .',\n",
       " 'our achiev global recognis today .',\n",
       " 'yet lack self-confid see develop nation , self-reli self-assur .',\n",
       " 'isn ’ incorrect ?',\n",
       " 'I third vision .',\n",
       " 'india must stand world .',\n",
       " 'becaus I believ unless india stand world , one respect us .',\n",
       " 'onli strength respect strength .',\n",
       " 'We must strong militari power also econom power .',\n",
       " 'both must go hand-in-hand .',\n",
       " 'My good fortun work three great mind .',\n",
       " 'dr. vikram sarabhai dept .',\n",
       " 'space , professor satish dhawan , succeed dr. brahm prakash , father nuclear materi .',\n",
       " 'I lucki work three close consid great opportun life .',\n",
       " 'I see four mileston career']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "pWntKnKbat5u"
   },
   "outputs": [],
   "source": [
    "# problem with stemming\n",
    "# produced intermediated representatione of word has may not have any meaning.\n",
    "# eg. fina, intelligen(),peopl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "_cSFRt-JbtGK"
   },
   "outputs": [],
   "source": [
    " # lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjip9zaStr5G",
    "outputId": "f8ec1185-a33f-4d4b-b6d2-d984dfad6c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "EV47t_HfsR_Z"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "KhGISo8bskbd"
   },
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "f3Q_ZwBdspb2"
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "YoFZoSVns0B9"
   },
   "outputs": [],
   "source": [
    "# create object for lemmatization\n",
    "lemmatizaer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "czGRwaoHtIwK"
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "  words = nltk.word_tokenize(sentences[i])\n",
    "  words = [lemmatizaer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "  sentences[i] = ' '.join(words)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7QorzXvtm6I",
    "outputId": "158c9e81-1219-43b1-8c5f-830e63274165"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I three vision India .',\n",
       " 'In 3000 year history , people world come invaded u , captured land , conquered mind .',\n",
       " 'From Alexander onwards , Greeks , Turks , Moguls , Portuguese , British , French , Dutch , came looted u , took .',\n",
       " 'Yet done nation .',\n",
       " 'We conquered anyone .',\n",
       " 'We grabbed land , culture , history tried enforce way life .',\n",
       " 'Why ?',\n",
       " 'Because respect freedom others.That first vision freedom .',\n",
       " 'I believe India got first vision 1857 , started War Independence .',\n",
       " 'It freedom must protect nurture build .',\n",
       " 'If free , one respect u .',\n",
       " 'My second vision India ’ development .',\n",
       " 'For fifty year developing nation .',\n",
       " 'It time see developed nation .',\n",
       " 'We among top 5 nation world term GDP .',\n",
       " 'We 10 percent growth rate area .',\n",
       " 'Our poverty level falling .',\n",
       " 'Our achievement globally recognised today .',\n",
       " 'Yet lack self-confidence see developed nation , self-reliant self-assured .',\n",
       " 'Isn ’ incorrect ?',\n",
       " 'I third vision .',\n",
       " 'India must stand world .',\n",
       " 'Because I believe unless India stand world , one respect u .',\n",
       " 'Only strength respect strength .',\n",
       " 'We must strong military power also economic power .',\n",
       " 'Both must go hand-in-hand .',\n",
       " 'My good fortune worked three great mind .',\n",
       " 'Dr. Vikram Sarabhai Dept .',\n",
       " 'space , Professor Satish Dhawan , succeeded Dr. Brahm Prakash , father nuclear material .',\n",
       " 'I lucky worked three closely consider great opportunity life .',\n",
       " 'I see four milestone career']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "-sAukZ3RtyYW"
   },
   "outputs": [],
   "source": [
    "# bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "dMEHjhI1wig1"
   },
   "outputs": [],
   "source": [
    "# Cleaning the texts\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "TPoB8c-SxMpt"
   },
   "outputs": [],
   "source": [
    "wordnet=WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Z5gzZvusl_Y",
    "outputId": "9a622894-5bb8-475c-ccd9-91af5bd2c8b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'years',\n",
       " 'of',\n",
       " 'our',\n",
       " 'history',\n",
       " 'people',\n",
       " 'from',\n",
       " 'all',\n",
       " 'over',\n",
       " 'the',\n",
       " 'world',\n",
       " 'have',\n",
       " 'come',\n",
       " 'and',\n",
       " 'invaded',\n",
       " 'us',\n",
       " 'captured',\n",
       " 'our',\n",
       " 'lands',\n",
       " 'conquered',\n",
       " 'our',\n",
       " 'minds']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = re.sub('[^a-zA-Z]', ' ', sentences[1])\n",
    "x = review.lower()\n",
    "x = x.split()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "gS47zbYDzFRY"
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "S2a3ub9JzFU2",
    "outputId": "8b203c7d-3f65-435e-a257-46e0effe4862"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'In 3000 years of our history, people from all over \\n               the world have come and invaded us, captured our lands, conquered our minds.'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "SQHvYO9GzTqw",
    "outputId": "8ad08d25-6a0f-459f-ae73-f2e6c74b710b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'year history people world come invaded u captured land conquered mind'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "ZkoqQDdCxiNE"
   },
   "outputs": [],
   "source": [
    "# create bag of words \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFRB1uuU0Y0Y",
    "outputId": "8fd7c6f7-c5d1-4009-8218-f8c12cde2366"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTz9KVws5nCU",
    "outputId": "f0a01815-5b4b-4ac3-843e-3a0a922f99d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAZySybC5tD4",
    "outputId": "8cb04403-f07a-4073-aaf7-e9aad2a22d9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R73SS4AA0b75",
    "outputId": "3bd828ff-bd26-4112-eef9-5d1aa3151784"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 114)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape     #   31 sentence ,114 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "VWPLdILJ04nF"
   },
   "outputs": [],
   "source": [
    "# TF - TERM FREQUNCY\n",
    "# IDF - INVERSE DOCUMENT FREQUNCY\n",
    "# TF - no.of repatione of word in senetense/no. of words in sentense\n",
    "#IDF - log(total no .of senetense/no.of sentense containg given words)\n",
    "# finally we have to do that\n",
    "# TF*IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "JVoZHP_L4Jen"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Cleaning the texts\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "gtyBW-Y54O7A"
   },
   "outputs": [],
   "source": [
    "wordnet=WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "9EzvISRY4ROE"
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "pTEsjlTR4U2Z"
   },
   "outputs": [],
   "source": [
    "    \n",
    "# Creating the TF-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5mE3hbJ4YIK",
    "outputId": "4cb97834-be9e-4bac-f9f9-52ede968901c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.25883507, 0.30512561,\n",
       "        0.        ],\n",
       "       [0.        , 0.28867513, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldx93jdF6Lcl",
    "outputId": "ff7a8319-93c1-4a08-ce7d-b91d64511d9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34186848, 0.        , 0.        ,\n",
       "       0.34186848, 0.        , 0.30512561, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.30512561,\n",
       "       0.        , 0.        , 0.        , 0.34186848, 0.        ,\n",
       "       0.30512561, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.30512561, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.34186848, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.25883507, 0.30512561, 0.        ])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVbQKkiU4ZQC",
    "outputId": "3508cf7a-12ca-4d60-ec82-ff4c786b8579"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 114)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "R-CVpSP5nBQ9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyELCbFunySW"
   },
   "source": [
    "Word embedding implements language modeling and feature extraction based techniques to map a word to vectors of real numbers. Some of the popular word embedding methods are:\n",
    "1.Binary Encoding.\n",
    "2.TF-IDF Encoding.\n",
    "3..Word2Vec Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "5GMIEoYY4whL"
   },
   "outputs": [],
   "source": [
    "# word to vec\n",
    "# word2Vec\n",
    "# apply for huge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "5w7PBvf58Alx"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "oNHOEgB38BS6"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "text = re.sub(r'[^a-zA-Z]', ' ',paragraph)\n",
    "\n",
    "text = text.lower()\n",
    "text = re.sub(r'\\s+',' ',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "M158Q9m0CS-k",
    "outputId": "daa1738e-5faa-4dea-b266-76cd9520b225"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'i have three visions for india in years of our history people from all over the world have come and invaded us captured our lands conquered our minds from alexander onwards the greeks the turks the moguls the portuguese the british the french the dutch all of them came and looted us took over what was ours yet we have not done this to any other nation we have not conquered anyone we have not grabbed their land their culture their history and tried to enforce our way of life on them why because we respect the freedom of others that is why my first vision is that of freedom i believe that india got its first vision of this in when we started the war of independence it is this freedom that we must protect and nurture and build on if we are not free no one will respect us my second vision for india s development for fifty years we have been a developing nation it is time we see ourselves as a developed nation we are among the top nations of the world in terms of gdp we have a percent growth rate in most areas our poverty levels are falling our achievements are being globally recognised today yet we lack the self confidence to see ourselves as a developed nation self reliant and self assured isn t this incorrect i have a third vision india must stand up to the world because i believe that unless india stands up to the world no one will respect us only strength respects strength we must be strong not only as a military power but also as an economic power both must go hand in hand my good fortune was to have worked with three great minds dr vikram sarabhai of the dept of space professor satish dhawan who succeeded him and dr brahm prakash father of nuclear material i was lucky to have worked with all three of them closely and consider this the great opportunity of my life i see four milestones in my career'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "U1oyq-uv8Gvr"
   },
   "outputs": [],
   "source": [
    "# Preparing the dataset\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "mpPVonGd8Ov1"
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [word for word in sentences[i] if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qHTjJiwl4jMA",
    "outputId": "2311dfc8-360b-4071-8120-148bb7bbe556"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['three',\n",
       "  'visions',\n",
       "  'india',\n",
       "  'years',\n",
       "  'history',\n",
       "  'people',\n",
       "  'world',\n",
       "  'come',\n",
       "  'invaded',\n",
       "  'us',\n",
       "  'captured',\n",
       "  'lands',\n",
       "  'conquered',\n",
       "  'minds',\n",
       "  'alexander',\n",
       "  'onwards',\n",
       "  'greeks',\n",
       "  'turks',\n",
       "  'moguls',\n",
       "  'portuguese',\n",
       "  'british',\n",
       "  'french',\n",
       "  'dutch',\n",
       "  'came',\n",
       "  'looted',\n",
       "  'us',\n",
       "  'took',\n",
       "  'yet',\n",
       "  'done',\n",
       "  'nation',\n",
       "  'conquered',\n",
       "  'anyone',\n",
       "  'grabbed',\n",
       "  'land',\n",
       "  'culture',\n",
       "  'history',\n",
       "  'tried',\n",
       "  'enforce',\n",
       "  'way',\n",
       "  'life',\n",
       "  'respect',\n",
       "  'freedom',\n",
       "  'others',\n",
       "  'first',\n",
       "  'vision',\n",
       "  'freedom',\n",
       "  'believe',\n",
       "  'india',\n",
       "  'got',\n",
       "  'first',\n",
       "  'vision',\n",
       "  'started',\n",
       "  'war',\n",
       "  'independence',\n",
       "  'freedom',\n",
       "  'must',\n",
       "  'protect',\n",
       "  'nurture',\n",
       "  'build',\n",
       "  'free',\n",
       "  'one',\n",
       "  'respect',\n",
       "  'us',\n",
       "  'second',\n",
       "  'vision',\n",
       "  'india',\n",
       "  'development',\n",
       "  'fifty',\n",
       "  'years',\n",
       "  'developing',\n",
       "  'nation',\n",
       "  'time',\n",
       "  'see',\n",
       "  'developed',\n",
       "  'nation',\n",
       "  'among',\n",
       "  'top',\n",
       "  'nations',\n",
       "  'world',\n",
       "  'terms',\n",
       "  'gdp',\n",
       "  'percent',\n",
       "  'growth',\n",
       "  'rate',\n",
       "  'areas',\n",
       "  'poverty',\n",
       "  'levels',\n",
       "  'falling',\n",
       "  'achievements',\n",
       "  'globally',\n",
       "  'recognised',\n",
       "  'today',\n",
       "  'yet',\n",
       "  'lack',\n",
       "  'self',\n",
       "  'confidence',\n",
       "  'see',\n",
       "  'developed',\n",
       "  'nation',\n",
       "  'self',\n",
       "  'reliant',\n",
       "  'self',\n",
       "  'assured',\n",
       "  'incorrect',\n",
       "  'third',\n",
       "  'vision',\n",
       "  'india',\n",
       "  'must',\n",
       "  'stand',\n",
       "  'world',\n",
       "  'believe',\n",
       "  'unless',\n",
       "  'india',\n",
       "  'stands',\n",
       "  'world',\n",
       "  'one',\n",
       "  'respect',\n",
       "  'us',\n",
       "  'strength',\n",
       "  'respects',\n",
       "  'strength',\n",
       "  'must',\n",
       "  'strong',\n",
       "  'military',\n",
       "  'power',\n",
       "  'also',\n",
       "  'economic',\n",
       "  'power',\n",
       "  'must',\n",
       "  'go',\n",
       "  'hand',\n",
       "  'hand',\n",
       "  'good',\n",
       "  'fortune',\n",
       "  'worked',\n",
       "  'three',\n",
       "  'great',\n",
       "  'minds',\n",
       "  'dr',\n",
       "  'vikram',\n",
       "  'sarabhai',\n",
       "  'dept',\n",
       "  'space',\n",
       "  'professor',\n",
       "  'satish',\n",
       "  'dhawan',\n",
       "  'succeeded',\n",
       "  'dr',\n",
       "  'brahm',\n",
       "  'prakash',\n",
       "  'father',\n",
       "  'nuclear',\n",
       "  'material',\n",
       "  'lucky',\n",
       "  'worked',\n",
       "  'three',\n",
       "  'closely',\n",
       "  'consider',\n",
       "  'great',\n",
       "  'opportunity',\n",
       "  'life',\n",
       "  'see',\n",
       "  'four',\n",
       "  'milestones',\n",
       "  'career']]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "4u0ZdurX8wi7"
   },
   "outputs": [],
   "source": [
    "# Training the Word2Vec model\n",
    "model = Word2Vec(sentences, min_count=1)   # if word is present less then 1 , i am going to skip this word , so you can set 2 ,5\n",
    "                                            # that means i consider all words \n",
    "\n",
    "words = model.wv.vocab   # i store vocablary in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MHoVVGj9_h9",
    "outputId": "f0accd16-bfc3-4ce9-acbf-3d6e8817a23e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achievements': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7fcd0>,\n",
       " 'alexander': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71790>,\n",
       " 'also': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec72890>,\n",
       " 'among': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7dd90>,\n",
       " 'anyone': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71d90>,\n",
       " 'areas': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7fa50>,\n",
       " 'assured': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9edd0>,\n",
       " 'believe': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d390>,\n",
       " 'brahm': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83310>,\n",
       " 'british': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71b10>,\n",
       " 'build': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d8d0>,\n",
       " 'came': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71ad0>,\n",
       " 'captured': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71590>,\n",
       " 'career': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec834d0>,\n",
       " 'closely': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83490>,\n",
       " 'come': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71290>,\n",
       " 'confidence': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9e210>,\n",
       " 'conquered': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec716d0>,\n",
       " 'consider': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec833d0>,\n",
       " 'culture': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7ded0>,\n",
       " 'dept': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83190>,\n",
       " 'developed': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7dad0>,\n",
       " 'developing': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7db10>,\n",
       " 'development': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7da50>,\n",
       " 'dhawan': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83290>,\n",
       " 'done': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71c90>,\n",
       " 'dr': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83090>,\n",
       " 'dutch': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71c10>,\n",
       " 'economic': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec72d10>,\n",
       " 'enforce': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7df10>,\n",
       " 'falling': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7ffd0>,\n",
       " 'father': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83390>,\n",
       " 'fifty': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d910>,\n",
       " 'first': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d2d0>,\n",
       " 'fortune': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec72f10>,\n",
       " 'four': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83450>,\n",
       " 'free': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d790>,\n",
       " 'freedom': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d090>,\n",
       " 'french': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec719d0>,\n",
       " 'gdp': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7fb90>,\n",
       " 'globally': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7fa10>,\n",
       " 'go': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec722d0>,\n",
       " 'good': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec72150>,\n",
       " 'got': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d110>,\n",
       " 'grabbed': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71f10>,\n",
       " 'great': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec72090>,\n",
       " 'greeks': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec718d0>,\n",
       " 'growth': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7ff50>,\n",
       " 'hand': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec720d0>,\n",
       " 'history': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71210>,\n",
       " 'incorrect': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9e910>,\n",
       " 'independence': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d6d0>,\n",
       " 'india': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec81ed0>,\n",
       " 'invaded': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71110>,\n",
       " 'lack': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9e810>,\n",
       " 'land': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7df50>,\n",
       " 'lands': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71450>,\n",
       " 'levels': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7f950>,\n",
       " 'life': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7df90>,\n",
       " 'looted': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71cd0>,\n",
       " 'lucky': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83350>,\n",
       " 'material': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83410>,\n",
       " 'milestones': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83590>,\n",
       " 'military': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec72c10>,\n",
       " 'minds': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71510>,\n",
       " 'moguls': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71a50>,\n",
       " 'must': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d4d0>,\n",
       " 'nation': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71fd0>,\n",
       " 'nations': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7dd50>,\n",
       " 'nuclear': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec832d0>,\n",
       " 'nurture': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d590>,\n",
       " 'one': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d990>,\n",
       " 'onwards': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71690>,\n",
       " 'opportunity': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83510>,\n",
       " 'others': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7de10>,\n",
       " 'people': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec711d0>,\n",
       " 'percent': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7fed0>,\n",
       " 'portuguese': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71810>,\n",
       " 'poverty': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7ff90>,\n",
       " 'power': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec72050>,\n",
       " 'prakash': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83250>,\n",
       " 'professor': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83210>,\n",
       " 'protect': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d810>,\n",
       " 'rate': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7fe90>,\n",
       " 'recognised': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7fbd0>,\n",
       " 'reliant': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9e850>,\n",
       " 'respect': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7de50>,\n",
       " 'respects': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9ee90>,\n",
       " 'sarabhai': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83050>,\n",
       " 'satish': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83150>,\n",
       " 'second': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d850>,\n",
       " 'see': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7dc10>,\n",
       " 'self': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9e110>,\n",
       " 'space': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec830d0>,\n",
       " 'stand': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9e4d0>,\n",
       " 'stands': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9ee10>,\n",
       " 'started': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d550>,\n",
       " 'strength': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9eed0>,\n",
       " 'strong': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9efd0>,\n",
       " 'succeeded': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec831d0>,\n",
       " 'terms': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7f990>,\n",
       " 'third': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9e510>,\n",
       " 'three': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec81f50>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d9d0>,\n",
       " 'today': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9ecd0>,\n",
       " 'took': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71b50>,\n",
       " 'top': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7dbd0>,\n",
       " 'tried': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7dfd0>,\n",
       " 'turks': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71710>,\n",
       " 'unless': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec9e650>,\n",
       " 'us': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71410>,\n",
       " 'vikram': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec83110>,\n",
       " 'vision': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d050>,\n",
       " 'visions': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec81d90>,\n",
       " 'war': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7d310>,\n",
       " 'way': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec7de90>,\n",
       " 'worked': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec72410>,\n",
       " 'world': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71490>,\n",
       " 'years': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec81f90>,\n",
       " 'yet': <gensim.models.keyedvectors.Vocab at 0x7f2a1ec71e90>}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words    # for each word assign some vector valu with 100 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "7vDVUsd983a1"
   },
   "outputs": [],
   "source": [
    "# Finding Word Vectors # for particular words\n",
    "vector = model.wv['war']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64b49z4Z9M51",
    "outputId": "8587fa55-d86a-42a8-e745-3fac04c1f61a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8650297e-03,  1.6706659e-03,  2.4406910e-03,  3.5519383e-03,\n",
       "       -3.9815824e-03,  6.2207738e-04, -2.2797843e-03,  3.1668162e-03,\n",
       "        2.7164822e-03, -3.2373050e-03,  2.2834665e-03, -1.5544096e-03,\n",
       "       -2.9071942e-03,  1.5815783e-04,  3.7387712e-03,  4.1893013e-03,\n",
       "        3.6622118e-03, -1.2604741e-03, -1.7809934e-03,  1.8310072e-03,\n",
       "        2.2957944e-03,  1.3028426e-03,  3.6072156e-03, -4.4648894e-03,\n",
       "        7.6652772e-04, -3.5634178e-03, -2.6206551e-03, -2.6026925e-03,\n",
       "        2.8611580e-03,  3.1766709e-04, -4.6182140e-03,  1.7853223e-03,\n",
       "       -3.5161744e-03,  1.4649789e-03, -1.8217760e-03, -4.6826112e-03,\n",
       "       -2.4732335e-03,  1.8928945e-03, -1.3366339e-03,  2.9671886e-03,\n",
       "       -4.4126492e-03, -2.3746120e-03, -3.9993014e-04,  2.3445196e-03,\n",
       "       -1.1927058e-03, -2.4297459e-03, -9.4844052e-04,  6.1427301e-04,\n",
       "        3.6676063e-03,  1.7807796e-03, -5.5024179e-04, -4.1950829e-03,\n",
       "       -1.7345051e-03,  2.1781200e-04, -5.3719548e-04, -4.9040900e-03,\n",
       "        3.2623648e-03, -2.5591496e-03,  2.5250204e-03, -6.2683423e-04,\n",
       "        3.4510095e-03, -3.4824819e-03, -2.6541527e-05,  2.6087051e-03,\n",
       "        1.2705049e-03,  3.9442228e-03,  2.7287516e-03,  4.5179785e-03,\n",
       "        2.0453515e-03, -7.1285589e-04,  9.3780429e-04, -4.8427456e-03,\n",
       "        4.3487027e-03,  3.6148431e-03, -3.5046106e-03,  4.8466460e-03,\n",
       "       -4.4723242e-04, -3.4058751e-03, -2.0002465e-04,  3.4410299e-03,\n",
       "        1.5703888e-03,  1.2928487e-03,  1.4518000e-03, -9.0321474e-04,\n",
       "        4.4734455e-03,  4.0013692e-03, -7.2056107e-04, -2.4940106e-03,\n",
       "        3.7391412e-03, -2.1062876e-04,  4.2337523e-04,  4.2737694e-03,\n",
       "       -1.6374930e-03,  3.2377196e-03,  2.6958392e-03, -4.3252930e-03,\n",
       "       -2.1222124e-03,  7.5643766e-04,  3.2195351e-03, -3.6182017e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svTyOSPkF3RQ",
    "outputId": "94789d0f-198d-47cd-c6d9-f258a4e6b32c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "ns8moji19CKQ"
   },
   "outputs": [],
   "source": [
    "# Most similar words related to war\n",
    "similar = model.wv.most_similar('war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7E329XPi9E68",
    "outputId": "4795bc51-6899-4041-de28-78f2a46e7f9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reliant', 0.29232653975486755),\n",
       " ('succeeded', 0.19974401593208313),\n",
       " ('lands', 0.1755051612854004),\n",
       " ('four', 0.15267696976661682),\n",
       " ('career', 0.14852923154830933),\n",
       " ('visions', 0.1370965540409088),\n",
       " ('worked', 0.13535019755363464),\n",
       " ('alexander', 0.1348946988582611),\n",
       " ('top', 0.1288912296295166),\n",
       " ('turks', 0.12541702389717102)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "W4etw4JnjBPe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kGnvwMquE_Cd",
    "outputId": "57418de1-75af-4da1-ce88-10f68dc7da7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "sqS1T41XjC4G"
   },
   "outputs": [],
   "source": [
    "# importing the Dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "messages = pd.read_csv('/content/drive/MyDrive/smsspamcollection/SMSSpamCollection', sep='\\t',\n",
    "                           names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoV9wUGcjuK7",
    "outputId": "02c1414c-7912-4ddc-862e-bd52595f651e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Data cleaning and preprocessing\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "mIETUko4j85c"
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "8NbjLft4kBEM"
   },
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "y=pd.get_dummies(messages['label'])\n",
    "y=y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "9nDl7JptkKlO"
   },
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "DadrKpzRkPTP"
   },
   "outputs": [],
   "source": [
    "# Training model using Naive bayes classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred=spam_detect_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rW6fSEvbkWsF",
    "outputId": "0f2941f3-364b-4a3a-a7ed-3653bc5e11a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWRlD2mtFU3W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "nlp_dp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
